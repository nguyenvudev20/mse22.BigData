{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I. (30 marks) Below are the theoretical session, which requires you to write down in thw cell \"Text\" in the notebook:\n",
        "1. Could you list out the main challenges of concurrency?\n",
        "2. Could you describe shortly about MapReduce? Please provide an example of MapReduce.\n",
        "3. Provide a high level comparison of Apache Hadoop and Apache Spark.\n",
        "4. What are the advantages of Apache Spark?\n",
        "5. Provide a comparison of RDD and DataFrame in Spark.  "
      ],
      "metadata": {
        "id": "V-S6ggQMmxvx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKcUsGyNk1cl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "II. (30 marks) You are given a file `appl_stock.csv`, please carry out the following tasks:\n",
        "\n",
        "1. Read this file by PySpark. Print out the schema.\n",
        "2. Create columns of `day of month`, `hour`, `day of year`, `month` from the column `Date` of the data.\n",
        "3. Using `groupby` and `year()` function to compute the average closing price per year."
      ],
      "metadata": {
        "id": "S9_563ulpsh9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_q690ZRq5kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "III. (40 marks) You are given a data `customer_churn.csv`, which describes the churn status in clients of a marletting agency. As a data scientist, you are required to create a machine learning model **in Spark** that will help predict which customers will churn (stop buying their service). A short description of the data is as follow:\n",
        "```\n",
        "Name : Name of the latest contact at Company\n",
        "Age: Customer Age\n",
        "Total_Purchase: Total Ads Purchased\n",
        "Account_Manager: Binary 0=No manager, 1= Account manager assigned\n",
        "Years: Totaly Years as a customer\n",
        "Num_sites: Number of websites that use the service.\n",
        "Onboard_date: Date that the name of the latest contact was onboarded\n",
        "Location: Client HQ Address\n",
        "Company: Name of Client Company\n",
        "```\n",
        "\n",
        "1. Read, print the schema and check out the data to set the first sight of the data.\n",
        "2. Format the data according to `VectorAssembler`, which is supported in MLlib of PySpark.\n",
        "3. Split the data into train/test data, and then fit train data to the logistic regression model.\n",
        "4. Evaluate the results and compute the AUC."
      ],
      "metadata": {
        "id": "brQ8gRaUshXy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fN4Zb88PtzCL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}